{"cells":[{"cell_type":"markdown","metadata":{},"source":["# MODELOS 1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["---------- Fonte de dados ---------------\n","Arquivo:'G:\\Meu Drive\\Mestrado\\Dados\\consolidado_DESFECHO_V2.csv'\n","Criado após correção do agrupamento dos db origem\n","Contém todas variáveis\n","Processada variável DESFECHO (Variável EVOLUCAO agregada em DESFECHO e removida. registros com EVOLUCAO nulos removidos)\n","\n","----------\n","---------- Processamentos ---------------\n","0 - Removidos: registros notificados em 2022 \n","1 - Removidos: Numero de registros menores de 18a  6975\n","2 - CS_RACA agrupada em RacaBranca (branco = 1, demais = 0)\n","----------\n","---------- Variáveis ---------------\n","VARIÁVEIS FINAIS:\n","'CS_SEXO', 'CS_ESCOL_N', 'FEBRE', 'TOSSE', 'DISPNEIA', 'DESC_RESP', 'SATURACAO', 'DIARREIA', 'OUTRO_SIN',  'OBESIDADE', 'OUT_MORBI', 'FADIGA', 'CL_tmp_p_inter', 'CT_IDADE', 'RacaBranca', 'CS_ZONA_CAT','DIABETES', 'CARDIOPATI'\n","\n","REMOVIDAS COLINEARIDADE: \n","'GARGANTA', 'ASMA', 'PNEUMOPATI',  'PERD_PALA', 'DOR_ABD', 'PERD_OLFT', 'VOMITO'\n","\n","----------\n","---------- OBS ---------------\n","RacaBranca e CS_SEXO são vairáveis binárias, mas foram processadas com o dummy. Isso não impacta no modelo.\n","\n","################\n","# GradientBoostingClassifier\n","################\n","# Melhores parâmetros: {'learning_rate': 0.1, 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n","# Melhor score: 0.7311341191629455\n","################\n","# CATBOOST\n","################\n","# Melhores parâmetros: {'depth': 8, 'iterations': 100, 'l2_leaf_reg': 5, 'learning_rate': 0.1}\n","# Melhor score: 0.7308828985253862\n","################\n","# XGBOOST\n","################\n","#Melhores parâmetros: {'colsample_bytree': 1, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300, 'subsample': 0.8}\n","#Melhor score: 0.7318569701353426\n","################\n","# LGBMClassifier\n","################\n","# Melhores parâmetros: {'lambda_l1': 1.5, 'lambda_l2': 1, 'min_data_in_leaf': 30, 'num_leaves': 127, 'reg_alpha': 0.1}\n","# Melhor score: 0.7360495182338803\n","################\n","# RandomForestClassifier\n","################\n","# Melhores parâmetros: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 300}\n","# Melhor score: 0.7255740734607775\n","################\n","# LogisticRegression\n","################\n","# Melhores parâmetros: {'C': 0.012742749857031334, 'penalty': 'l1', 'solver': 'liblinear'}\n","# Melhor score (acurácia): 0.7264723132337565"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Carga do df\n","df = pd.read_csv('consolidado_DESFECHO_V2.csv')\n","\n","# Seleção das variáveis de interesse\n","df = df[[ 'DESFECHO',\n","'ANO_SEM_NOT',\n","\"DT_SIN_PRI\",\n","\"CS_SEXO\",\n","\"NU_IDADE_N\",\n","\"CS_RACA\",\n","\"CS_ESCOL_N\",\n","\"CS_ZONA\",\n","\"FEBRE\",\n","\"TOSSE\",\n","\"GARGANTA\",\n","\"DISPNEIA\",\n","\"DESC_RESP\",\n","\"SATURACAO\",\n","\"DIARREIA\",\n","\"VOMITO\",\n","\"OUTRO_SIN\",\n","\"FATOR_RISC\",\n","\"CARDIOPATI\",\n","\"ASMA\",\n","\"DIABETES\",\n","\"PNEUMOPATI\",\n","\"OBESIDADE\",\n","\"OUT_MORBI\",\n","\"DT_INTERNA\",\n","\"DOR_ABD\",\n","\"FADIGA\",\n","\"PERD_OLFT\",\n","\"PERD_PALA\"] ]\n","\n","#Removendo Registros de 2022\n","print('Numero de registros iniciais ', len(df))\n","print('Numero de registros menores de 2022 ', len(df['ANO_SEM_NOT'].astype(str).str[0:2] == \"22\"))\n","df = df[df['ANO_SEM_NOT'].astype(str).str[0:2] != \"22\"]\n","print('Numero de registros do df final ', len(df))\n","print()\n","\n","\n","#Removendo Registros de menores de 18a\n","print('Numero de registros iniciais ', len(df))\n","print('Numero de registros menores de 18a ', len(df[df.NU_IDADE_N < 18]))\n","df = df[df.NU_IDADE_N > 17]\n","print('Numero de registros do df final ', len(df))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#####################################\n","#### Processamento das variáveis\n","#####################################\n","#######\n","#### CRIACAO VARIÁVEL 'delta_sintomas_internação'\n","# Criando variáveis no df\n","df['DT_INTERNA'] = pd.to_datetime(df['DT_INTERNA'],format='%d/%m/%Y', errors = 'coerce')\n","df['DT_SIN_PRI'] = pd.to_datetime(df['DT_SIN_PRI'],format='%d/%m/%Y', errors = 'coerce')\n","df[ 'delta_sintomas_internação'] = (df[ 'DT_INTERNA'] - df[ 'DT_SIN_PRI']).dt.days\n","df['CL_tmp_p_inter'] = np.where(df['delta_sintomas_internação'].between(0, 4), 'tmp_p_inter_1',\n","         np.where(df['delta_sintomas_internação'].between(5, 7), 'tmp_p_inter_2',\n","         np.where(df['delta_sintomas_internação'].between(8, 10), 'tmp_p_inter_3',\n","         np.where(df['delta_sintomas_internação'].between(11, 19), 'tmp_p_inter_4',\n","         'tmp_p_inter_5'))))\n","df = df.drop(columns=(['DT_INTERNA', 'DT_SIN_PRI','delta_sintomas_internação']))\n","#######\n","## CS_SEXO\n","##\n","# M - 0\n","# H - 1\n","# I - 1 (sao 11 registros)\n","\n","df['CS_SEXO'] = df['CS_SEXO'].replace({'H': 1, 'I': 1, 'F': 0, 'M': 0})\n","#####\n","## NU_IDADE_N\n","## Criação da categoria CT_IDADE\n","\n","\n","# Criação de bins para categorizar as idades\n","# Definindo os intervalos (bins)\n","bins = [0, 17, 49, 59, 69, 79, 140]\n","\n","# Definindo os rótulos para os intervalos\n","labels = ['0-17', '18-49', '50-59', '60-69', '70-79', '80-140']\n","\n","# Agrupando os dados na coluna 'valor_contínuo' nos intervalos definidos\n","df['CT_IDADE'] = pd.cut(df['NU_IDADE_N'], bins=bins, labels=labels, right=True)\n","\n","df = df.drop(columns=('NU_IDADE_N'))\n","#####\n","## CS_RACA\n","## Criação da categoria RacaBranca\n","var = 'CS_RACA'\n","df[var] = df[var].fillna(9)\n","df['RacaBranca'] = np.where(df[var] == 1, 1,0)\n","df = df.drop(columns=(var))\n","#####\n","## CS_ESCOL_N\n","## criada categoria para nulos\n","df['CS_ESCOL_N'] = df['CS_ESCOL_N'].fillna(8)\n","#Categorizaçao da variávvel CS_ZONA\n","#8 – NULO\n","#1 – URBANO\n","#2 - RURAL, PERIRURAL, IGNORALDO\n","\n","df['CS_ZONA'] = df['CS_ZONA'].fillna(8)\n","df['CS_ZONA_CAT'] = np.where( df['CS_ZONA']== 1, 1 , np.where(df['CS_ZONA']== 8, 0, 2))\n","df = df.drop(columns=('CS_ZONA'))\n","# Padronização das variáveis de sintomas e fatores de risco\n","#0 – NULO\n","#1 – Sim\n","#2 - Não\n","#9 - IGNORALDO\n","for var in ['FEBRE', \"TOSSE\", \"GARGANTA\", \"DISPNEIA\", \"DESC_RESP\",\"SATURACAO\", \"DIARREIA\", \"VOMITO\", \"OUTRO_SIN\", \"ASMA\", \"DIABETES\",  \"CARDIOPATI\", \"PNEUMOPATI\", \"OBESIDADE\",\"OUT_MORBI\", \"DOR_ABD\", \"FADIGA\", \"PERD_OLFT\", \"PERD_PALA\"]:\n","  df[var] = df[var].fillna(0)\n","  df[var] = df[var].replace({9: 0})\n","# Padronização da FATOR_RISC\n","#1 – Sim\n","#2 - Não\n","#9 - IGNORALDO\n","var = 'FATOR_RISC'\n","df[var] = df[var].replace({2: 0, 'S': 1, 'N':0 })"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["################\n","### Avaliação de Colinearidade\n","\n","corr = df.corr()\n","\n","# Gera um mapa de calor\n","plt.figure(figsize=(25, 25))\n","sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True, square=True, linewidths=.5)\n","\n","plt.title('Mapa de Calor da Colinearidade entre Variáveis')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Definidas vairáveis finais removendo as de alta colinearidade\n","df = df.drop(columns=['GARGANTA', 'ASMA', 'PNEUMOPATI',  'PERD_PALA', 'DOR_ABD', 'PERD_OLFT', 'VOMITO'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["################\n","### Criação das variáveis Dummy\n","### NOTA - CS_SEXO e RacaBranca são variáveis binarias, podem ser removidas desse processamento.\n","df = pd.get_dummies(df, columns=['CS_SEXO', 'CS_ESCOL_N', 'FEBRE', 'TOSSE', 'DISPNEIA', 'DESC_RESP', 'SATURACAO', 'DIARREIA', 'OUTRO_SIN',  'OBESIDADE', 'OUT_MORBI', 'FADIGA', 'CL_tmp_p_inter', 'CT_IDADE', 'RacaBranca', 'CS_ZONA_CAT',  \"DIABETES\", \"CARDIOPATI\"], drop_first=True)\n","\n","### Salvando banco de dados do modelo 2\n","df.to_csv('G:\\Meu Drive\\Mestrado\\Dados\\pre_modelagem.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["################\n","### Carga das bibliotecas para treinamento do modelo\n","\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import train_test_split\n","!pip install catboost\n","from catboost import CatBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","!pip install xgboost\n","import xgboost as xgb\n","!pip install lightgbm\n","import lightgbm as lgb\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["################\n","### Otimização de hiperparametros\n","################\n","###\n","# Preparação do df\n","# Removendo a coluna ANO_SEM_NOT Não será usada no modelo geral.\n","df = df.drop(columns=('ANO_SEM_NOT'))\n","df.FATOR_RISC = df.FATOR_RISC.astype(int)\n","#\n","###\n","\n","###\n","# Divisão em treino e teste\n","X_train, X_test, y_train, y_test = train_test_split(\n","    df.drop(columns=['DESFECHO']), # ou as colunas de features que você quer usar\n","    df['DESFECHO'], # a coluna alvo\n","    test_size=0.2, # define a proporção do teste para 20%\n","    random_state=42 # define a semente de aleatorização\n",")\n","#\n","###\n","\n","################\n","# GradientBoostingClassifier\n","################\n","# Melhores parâmetros: {'learning_rate': 0.1, 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n","# Melhor score: 0.7311341191629455\n","################\n","\n","\n","param_grid = {\n","    'n_estimators': [100, 200],\n","    'learning_rate': [0.01, 0.1],\n","    'max_depth': [3, 5],\n","    'min_samples_split': [2, 5],\n","    'min_samples_leaf': [1, 2]\n","}\n","\n","gb_clf = GradientBoostingClassifier(random_state=42)\n","grid_search = GridSearchCV(estimator=gb_clf, param_grid=param_grid, scoring='accuracy', cv=3, verbose=1, n_jobs=-1)\n","grid_search.fit(X_train, y_train)\n","\n","# Exibe os melhores parâmetros encontrados\n","print('Melhores parâmetros GradientBoostingClassifier:', grid_search.best_params_)\n","\n","# Exibe o melhor score\n","print('Melhor score GradientBoostingClassifier:', grid_search.best_score_)\n","\n","################\n","# CATBOOST\n","################\n","# Melhores parâmetros: {'depth': 8, 'iterations': 100, 'l2_leaf_reg': 5, 'learning_rate': 0.1}\n","# Melhor score: 0.7308828985253862\n","################\n","# Define o modelo\n","model = CatBoostClassifier()\n","\n","# Define o espaço de busca dos hiperparâmetros\n","param_grid = {\n","    'depth': [4, 6, 8],\n","    'learning_rate': [0.01, 0.05, 0.1],\n","    'iterations': [30, 50, 100],\n","    'l2_leaf_reg': [1, 3, 5]\n","}\n","\n","# Configura a busca em grade\n","grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1)\n","\n","# Executa a busca em grade\n","grid_search.fit(X_train, y_train)\n","\n","# Exibe os melhores parâmetros encontrados\n","print('Melhores parâmetros CatBoostClassifier:', grid_search.best_params_)\n","\n","# Exibe o melhor score\n","print('Melhor score CatBoostClassifier:', grid_search.best_score_)\n","\n","################\n","# XGBOOST\n","################\n","#Melhores parâmetros: {'colsample_bytree': 1, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300, 'subsample': 0.8}\n","#Melhor score: 0.7318569701353426\n","################\n","# Modelo base\n","model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n","\n","# Espaço de hiperparâmetros para a busca\n","param_grid = {\n","    'max_depth': [3, 4, 5],\n","    'learning_rate': [0.01, 0.1, 0.2],\n","    'n_estimators': [100, 200, 300],\n","    'subsample': [0.8, 1],\n","    'colsample_bytree': [0.8, 1],\n","}\n","\n","# Configuração do GridSearchCV\n","grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1)\n","\n","# Executa a busca em grade\n","grid_search.fit(X_train, y_train)\n","\n","# Melhores parâmetros e melhor score\n","print(\"Melhores parâmetros XGBClassifier:\", grid_search.best_params_)\n","print('Melhor score XGBClassifier:', grid_search.best_score_)\n","\n","\n","################\n","# LGBMClassifier\n","################\n","# Melhores parâmetros: {'lambda_l1': 1.5, 'lambda_l2': 1, 'min_data_in_leaf': 30, 'num_leaves': 127, 'reg_alpha': 0.1}\n","# Melhor score: 0.7360495182338803\n","################\n","\n","# Espaço de hiperparâmetros para a busca\n","param_grid = {\n","    'num_leaves': [31, 127],\n","    'reg_alpha': [0.1, 0.5],\n","    'min_data_in_leaf': [30, 50, 100],\n","    'lambda_l1': [0, 1, 1.5],\n","    'lambda_l2': [0, 1]\n","}\n","# Modelo base\n","gbm = lgb.LGBMClassifier(boosting_type='gbdt', objective='binary', random_state=42)\n","# Configuração do GridSearchCV\n","grid_search = GridSearchCV(estimator=gbm, param_grid=param_grid, scoring='accuracy', cv=3, verbose=1, n_jobs=-1)\n","# Executa a busca em grade\n","grid_search.fit(X_train, y_train)\n","\n","# Exibe os melhores parâmetros encontrados\n","print('Melhores parâmetros LGBMClassifier:', grid_search.best_params_)\n","\n","# Exibe o melhor score\n","print('Melhor score LGBMClassifier:', grid_search.best_score_)\n","\n","################\n","# RandomForestClassifier\n","################\n","# Melhores parâmetros: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 300}\n","# Melhor score: 0.7255740734607775\n","################\n","\n","\n","# Espaço de hiperparâmetros para a busca\n","param_grid = {\n","    'n_estimators': [200, 300],\n","    'max_depth': [10, 20],\n","    'min_samples_split': [2, 5]\n","}\n","# Modelo base\n","rf_clf = RandomForestClassifier(random_state=42)\n","# Configuração do GridSearchCV\n","grid_search = GridSearchCV(estimator=rf_clf, param_grid=param_grid, scoring='accuracy', cv=3, verbose=1, n_jobs=-1)\n","# Executa a busca em grade\n","grid_search.fit(X_train, y_train)\n","\n","# Exibe os melhores parâmetros encontrados\n","print('Melhores parâmetros RandomForestClassifier:', grid_search.best_params_)\n","\n","# Exibe o melhor score\n","print('Melhor score RandomForestClassifier:', grid_search.best_score_)\n","\n","\n","################\n","# LogisticRegression\n","################\n","# Melhores parâmetros: {'C': 0.012742749857031334, 'penalty': 'l1', 'solver': 'liblinear'}\n","# Melhor score (acurácia): 0.7264723132337565\n","#\n","################\n","# Definindo o espaço de parâmetros\n","param_grid = {\n","    'C': np.logspace(-4, 4, 20),  # Varia de 10^-4 a 10^4\n","    'penalty': ['l1', 'l2'],  # L1 é Lasso, L2 é Ridge\n","    'solver': ['liblinear']  # 'liblinear' é uma boa escolha para pequenos datasets e quando se usa a regularização L1\n","}\n","\n","# Instanciando o modelo de regressão logística\n","log_reg = LogisticRegression()\n","\n","# Instanciando o GridSearchCV\n","grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1, verbose=1)\n","\n","# Ajustando o GridSearchCV aos dados de treino\n","# Substitua X_train e y_train pelos seus dados de treinamento\n","grid_search.fit(X_train, y_train)\n","\n","# Exibindo os melhores parâmetros e o melhor score\n","print(\"Melhores parâmetros LogisticRegression:\", grid_search.best_params_)\n","print(\"Melhor score (acurácia) LogisticRegression:\", grid_search.best_score_)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["########\n","## Comparação do desempenho dos modelos.\n","\n","!pip install xgboost\n","!pip install catboost\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import roc_auc_score\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from catboost import CatBoostClassifier\n","from xgboost import XGBClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import roc_curve, auc\n","\n","# Criação de df treino e teste\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(\n","    df.drop(columns=['DESFECHO']), # ou as colunas de features que você quer usar\n","    df['DESFECHO'], # a coluna alvo\n","    test_size=0.2, # define a proporção do teste para 20%\n","    random_state=42) # define a semente de aleatorização\n","\n","# Convertendo y_test para um array do NumPy para evitar problemas de indexação\n","y_test = y_test.to_numpy() if hasattr(y_test, 'to_numpy') else y_test\n","\n","# Modelos\n","catboost_model = CatBoostClassifier(depth=8, iterations=100, l2_leaf_reg=5, learning_rate=0.1, verbose=0)\n","xgboost_model = XGBClassifier(colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8)\n","gradientboost = GradientBoostingClassifier(learning_rate= 0.1, max_depth= 5, min_samples_leaf = 1, min_samples_split= 5, n_estimators= 200)\n","randomforest_model = RandomForestClassifier(max_depth=20, min_samples_split=5, n_estimators=300)\n","logistic_model = LogisticRegression(C=0.012742749857031334, penalty='l1', solver='liblinear')\n","\n","\n","models = [catboost_model, xgboost_model, gradientboost, randomforest_model, logistic_model]\n","model_names = [\"CatBoost\", \"XGBoost\", 'GradientBoost', \"RandomForest\", \"LogisticRegression\"]\n","\n","plt.figure(figsize=(10, 8))\n","\n","for model, name in zip(models, model_names):\n","    model.fit(X_train, y_train)\n","    y_pred_proba = model.predict_proba(X_test)[:, 1]\n","    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n","    roc_auc = auc(fpr, tpr)\n","    plt.plot(fpr, tpr, label=f'{name} AUC = {roc_auc:.2f}')\n","    \n","    # Bootstrap para calcular o intervalo de confiança\n","    n_bootstraps = 1000\n","    bootstrapped_scores = []\n","    \n","    rng = np.random.RandomState(42)  # Reproducibilidade\n","    for i in range(n_bootstraps):\n","        # Bootstrap por amostragem com reposição nos índices dos dados de teste\n","        indices = rng.randint(0, len(y_pred_proba), len(y_pred_proba))\n","        if len(np.unique(y_test[indices])) < 2:\n","            # Se após a amostragem, há menos de duas classes, pule esta iteração\n","            continue\n","\n","        score = roc_auc_score(y_test[indices], y_pred_proba[indices])\n","        bootstrapped_scores.append(score)\n","        \n","    sorted_scores = np.array(bootstrapped_scores)\n","    sorted_scores.sort()\n","    \n","    # Calculando a confiança de 95%\n","    confidence_lower = sorted_scores[int(0.025 * len(sorted_scores))]\n","    confidence_upper = sorted_scores[int(0.975 * len(sorted_scores))]\n","    \n","    print(f\"{name}: AUC = {roc_auc:.3f} (95% CI: {confidence_lower:.3f} - {confidence_upper:.3f})\")\n","\n","plt.plot([0, 1], [0, 1], 'k--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC Curves')\n","plt.legend(loc=\"lower right\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# MODELOS 2"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["---------- Fonte de dados ---------------\n","Arquivo:'G:\\Meu Drive\\Mestrado\\Dados\\consolidado_DESFECHO_V2.csv'\n","Criado após correção do agrupamento dos db origem\n","Contém todas variáveis\n","Processada variável DESFECHO (Variável EVOLUCAO agregada em DESFECHO e removida. registros com EVOLUCAO nulos removidos)\n","\n","----------\n","---------- Processamentos ---------------\n","0 - Removidos: registros notificados em 2022 \n","1 - Removidos: Numero de registros menores de 18a  6975\n","2 - CS_RACA agrupada em RacaBranca (branco = 1, demais = 0)\n","----------\n","---------- Variáveis ---------------\n","VARIÁVEIS FINAIS:\n","'CS_SEXO', 'CS_ESCOL_N', 'FEBRE', 'TOSSE', 'DISPNEIA', 'DESC_RESP', 'SATURACAO', 'DIARREIA', 'OUTRO_SIN',  'OBESIDADE', 'OUT_MORBI', 'FADIGA', 'CL_tmp_p_inter', 'CT_IDADE', 'RacaBranca', 'CS_ZONA_CAT'\n","\n","REMOVIDAS COLINEARIDADE: \n","'GARGANTA', 'ASMA', 'PNEUMOPATI',  'PERD_PALA', 'DOR_ABD', 'PERD_OLFT', 'VOMITO', 'DIABETES', 'CARDIOPATI'\n","\n","----------\n","---------- OBS ---------------\n","RacaBranca e CS_SEXO são vairáveis binárias, mas foram processadas com o dummy. Isso não impacta no modelo.\n","\n","################\n","# CATBOOST\n","################\n","# Melhores parâmetros CatBoostClassifier: {'depth': 8, 'iterations': 100, 'l2_leaf_reg': 3, 'learning_rate': 0.1}\n","# Melhor score CatBoostClassifier: 0.7305036963486918\n","################\n","\n","################\n","# XGBOOST\n","################\n","#Melhores parâmetros: {'colsample_bytree': 1, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300, 'subsample': 0.8}\n","#Melhor score: 0.7318569701353426\n","################\n","\n","################\n","# LGBMClassifier\n","################\n","# Melhores parâmetros GradientBoostingClassifier: {'learning_rate': 0.1, 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n","# Melhor score GradientBoostingClassifier: 0.7304776262351679\n","################\n","\n","################\n","# RandomForestClassifier\n","################\n","# Melhores parâmetros RandomForestClassifier: {'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 200}\n","# Melhor score RandomForestClassifier: 0.7252304225924031\n","################\n","\n","\n","################\n","# LogisticRegression\n","################\n","# Melhores parâmetros LogisticRegression: {'C': 0.03359818286283781, 'penalty': 'l1', 'solver': 'liblinear'}\n","# Melhor score (acurácia) LogisticRegression: 0.7261736861897804\n","################"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["# Carga do df\n","df = pd.read_csv('G:\\Meu Drive\\Mestrado\\Dados\\consolidado_DESFECHO_V2.csv')\n","\n","# Seleção das variáveis de interesse\n","df = df[[ 'DESFECHO',\n","'ANO_SEM_NOT',\n","\"DT_SIN_PRI\",\n","\"CS_SEXO\",\n","\"NU_IDADE_N\",\n","\"CS_RACA\",\n","\"CS_ESCOL_N\",\n","\"CS_ZONA\",\n","\"FEBRE\",\n","\"TOSSE\",\n","\"GARGANTA\",\n","\"DISPNEIA\",\n","\"DESC_RESP\",\n","\"SATURACAO\",\n","\"DIARREIA\",\n","\"VOMITO\",\n","\"OUTRO_SIN\",\n","\"FATOR_RISC\",\n","\"CARDIOPATI\",\n","\"ASMA\",\n","\"DIABETES\",\n","\"PNEUMOPATI\",\n","\"OBESIDADE\",\n","\"OUT_MORBI\",\n","\"DT_INTERNA\",\n","\"DOR_ABD\",\n","\"FADIGA\",\n","\"PERD_OLFT\",\n","\"PERD_PALA\"] ]\n","\n","#Removendo Registros de 2022\n","print('Numero de registros iniciais ', len(df))\n","print('Numero de registros menores de 2022 ', len(df['ANO_SEM_NOT'].astype(str).str[0:2] == \"22\"))\n","df = df[df['ANO_SEM_NOT'].astype(str).str[0:2] != \"22\"]\n","print('Numero de registros do df final ', len(df))\n","print()\n","\n","\n","#Removendo Registros de menores de 18a\n","print('Numero de registros iniciais ', len(df))\n","print('Numero de registros menores de 18a ', len(df[df.NU_IDADE_N < 18]))\n","df = df[df.NU_IDADE_N > 17]\n","print('Numero de registros do df final ', len(df))"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["#####################################\n","#### Processamento das variáveis\n","#####################################\n","#######\n","#### CRIACAO VARIÁVEL 'delta_sintomas_internação'\n","# Criando variáveis no df\n","df['DT_INTERNA'] = pd.to_datetime(df['DT_INTERNA'],format='%d/%m/%Y', errors = 'coerce')\n","df['DT_SIN_PRI'] = pd.to_datetime(df['DT_SIN_PRI'],format='%d/%m/%Y', errors = 'coerce')\n","df[ 'delta_sintomas_internação'] = (df[ 'DT_INTERNA'] - df[ 'DT_SIN_PRI']).dt.days\n","df['CL_tmp_p_inter'] = np.where(df['delta_sintomas_internação'].between(0, 4), 'tmp_p_inter_1',\n","         np.where(df['delta_sintomas_internação'].between(5, 7), 'tmp_p_inter_2',\n","         np.where(df['delta_sintomas_internação'].between(8, 10), 'tmp_p_inter_3',\n","         np.where(df['delta_sintomas_internação'].between(11, 19), 'tmp_p_inter_4',\n","         'tmp_p_inter_5'))))\n","df = df.drop(columns=(['DT_INTERNA', 'DT_SIN_PRI','delta_sintomas_internação']))\n","#######\n","## CS_SEXO\n","##\n","# M - 0\n","# H - 1\n","# I - 1 (sao 11 registros)\n","\n","df['CS_SEXO'] = df['CS_SEXO'].replace({'H': 1, 'I': 1, 'F': 0, 'M': 0})\n","#####\n","## NU_IDADE_N\n","## Criação da categoria CT_IDADE\n","\n","\n","# Criação de bins para categorizar as idades\n","# Definindo os intervalos (bins)\n","bins = [0, 17, 49, 59, 69, 79, 140]\n","\n","# Definindo os rótulos para os intervalos\n","labels = ['0-17', '18-49', '50-59', '60-69', '70-79', '80-140']\n","\n","# Agrupando os dados na coluna 'valor_contínuo' nos intervalos definidos\n","df['CT_IDADE'] = pd.cut(df['NU_IDADE_N'], bins=bins, labels=labels, right=True)\n","\n","df = df.drop(columns=('NU_IDADE_N'))\n","#####\n","## CS_RACA\n","## Criação da categoria RacaBranca\n","var = 'CS_RACA'\n","df[var] = df[var].fillna(9)\n","df['RacaBranca'] = np.where(df[var] == 1, 1,0)\n","df = df.drop(columns=(var))\n","#####\n","## CS_ESCOL_N\n","## criada categoria para nulos\n","df['CS_ESCOL_N'] = df['CS_ESCOL_N'].fillna(8)\n","#Categorizaçao da variávvel CS_ZONA\n","#8 – NULO\n","#1 – URBANO\n","#2 - RURAL, PERIRURAL, IGNORALDO\n","\n","df['CS_ZONA'] = df['CS_ZONA'].fillna(8)\n","df['CS_ZONA_CAT'] = np.where( df['CS_ZONA']== 1, 1 , np.where(df['CS_ZONA']== 8, 0, 2))\n","df = df.drop(columns=('CS_ZONA'))\n","# Padronização das variáveis de sintomas e fatores de risco\n","#0 – NULO\n","#1 – Sim\n","#2 - Não\n","#9 - IGNORALDO\n","for var in ['FEBRE', \"TOSSE\", \"GARGANTA\", \"DISPNEIA\", \"DESC_RESP\",\"SATURACAO\", \"DIARREIA\", \"VOMITO\", \"OUTRO_SIN\", \"ASMA\", \"DIABETES\",  \"CARDIOPATI\", \"PNEUMOPATI\", \"OBESIDADE\",\"OUT_MORBI\", \"DOR_ABD\", \"FADIGA\", \"PERD_OLFT\", \"PERD_PALA\"]:\n","  df[var] = df[var].fillna(0)\n","  df[var] = df[var].replace({9: 0})\n","# Padronização da FATOR_RISC\n","#1 – Sim\n","#2 - Não\n","#9 - IGNORALDO\n","var = 'FATOR_RISC'\n","df[var] = df[var].replace({2: 0, 'S': 1, 'N':0 })"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["################\n","### Remoçao do índice ano_semana\n","\n","df = df.drop(columns=('ANO_SEM_NOT'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["################\n","### Avaliação de Colinearidade\n","\n","corr = df.corr()\n","\n","# Gera um mapa de calor\n","plt.figure(figsize=(25, 25))\n","sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True, square=True, linewidths=.5)\n","\n","plt.title('Mapa de Calor da Colinearidade entre Variáveis')\n","plt.show()"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["# Definidas vairáveis finais removendo as de alta colinearidade\n","df = df.drop(columns=['GARGANTA', 'ASMA', 'PNEUMOPATI',  'PERD_PALA', 'DOR_ABD', 'PERD_OLFT', 'VOMITO', \"DIABETES\", \"CARDIOPATI\"])"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["################\n","### Criação das variáveis Dummy\n","### NOTA - CS_SEXO e RacaBranca são variáveis binarias, podem ser removidas desse processamento.\n","df = pd.get_dummies(df, columns=['CS_SEXO', 'CS_ESCOL_N', 'FEBRE', 'TOSSE', 'DISPNEIA', 'DESC_RESP', 'SATURACAO', 'DIARREIA', 'OUTRO_SIN',  'OBESIDADE', 'OUT_MORBI', 'FADIGA', 'CL_tmp_p_inter', 'CT_IDADE', 'RacaBranca', 'CS_ZONA_CAT'], drop_first=True)\n","\n","### Salvando banco de dados do modelo 2\n","df.to_csv('G:\\Meu Drive\\Mestrado\\Dados\\pre_modelagem_modelo_2.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["################\n","### Carga das bibliotecas para treinamento do modelo\n","\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import train_test_split\n","!pip install catboost\n","from catboost import CatBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","!pip install xgboost\n","import xgboost as xgb\n","!pip install lightgbm\n","import lightgbm as lgb\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["################\n","### Otimização de hiperparametros\n","################\n","###\n","# Preparação do df\n","# Removendo a coluna ANO_SEM_NOT Não será usada no modelo geral.\n","df = df.drop(columns=('ANO_SEM_NOT'))\n","df.FATOR_RISC = df.FATOR_RISC.astype(int)\n","#\n","###\n","\n","###\n","# Divisão em treino e teste\n","X_train, X_test, y_train, y_test = train_test_split(\n","    df.drop(columns=['DESFECHO']), # ou as colunas de features que você quer usar\n","    df['DESFECHO'], # a coluna alvo\n","    test_size=0.2, # define a proporção do teste para 20%\n","    random_state=42 # define a semente de aleatorização\n",")\n","#\n","###\n","\n","################\n","# GradientBoostingClassifier\n","################\n","# Melhores parâmetros: {'learning_rate': 0.1, 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n","# Melhor score: 0.7304776262351679\n","################\n","\n","\n","param_grid = {\n","    'n_estimators': [100, 200],\n","    'learning_rate': [0.01, 0.1],\n","    'max_depth': [3, 5],\n","    'min_samples_split': [2, 5],\n","    'min_samples_leaf': [1, 2]\n","}\n","\n","gb_clf = GradientBoostingClassifier(random_state=42)\n","grid_search = GridSearchCV(estimator=gb_clf, param_grid=param_grid, scoring='accuracy', cv=3, verbose=1, n_jobs=-1)\n","grid_search.fit(X_train, y_train)\n","\n","# Exibe os melhores parâmetros encontrados\n","print('Melhores parâmetros GradientBoostingClassifier:', grid_search.best_params_)\n","\n","# Exibe o melhor score\n","print('Melhor score GradientBoostingClassifier:', grid_search.best_score_)\n","\n","################\n","# CATBOOST\n","################\n","# Melhores parâmetros CatBoostClassifier: {'depth': 8, 'iterations': 100, 'l2_leaf_reg': 3, 'learning_rate': 0.1}\n","# Melhor score CatBoostClassifier: 0.7305036963486918\n","################\n","# Define o modelo\n","model = CatBoostClassifier()\n","\n","# Define o espaço de busca dos hiperparâmetros\n","param_grid = {\n","    'depth': [4, 6, 8],\n","    'learning_rate': [0.01, 0.05, 0.1],\n","    'iterations': [30, 50, 100],\n","    'l2_leaf_reg': [1, 3, 5]\n","}\n","\n","# Configura a busca em grade\n","grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1)\n","\n","# Executa a busca em grade\n","grid_search.fit(X_train, y_train)\n","\n","# Exibe os melhores parâmetros encontrados\n","print('Melhores parâmetros CatBoostClassifier:', grid_search.best_params_)\n","\n","# Exibe o melhor score\n","print('Melhor score CatBoostClassifier:', grid_search.best_score_)\n","\n","################\n","# XGBOOST\n","################\n","#Melhores parâmetros: {'colsample_bytree': 1, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300, 'subsample': 0.8}\n","#Melhor score: 0.7318569701353426\n","################\n","# Modelo base\n","model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n","\n","# Espaço de hiperparâmetros para a busca\n","param_grid = {\n","    'max_depth': [3, 4, 5],\n","    'learning_rate': [0.01, 0.1, 0.2],\n","    'n_estimators': [100, 200, 300],\n","    'subsample': [0.8, 1],\n","    'colsample_bytree': [0.8, 1],\n","}\n","\n","# Configuração do GridSearchCV\n","grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1)\n","\n","# Executa a busca em grade\n","grid_search.fit(X_train, y_train)\n","\n","# Melhores parâmetros e melhor score\n","print(\"Melhores parâmetros XGBClassifier:\", grid_search.best_params_)\n","print('Melhor score XGBClassifier:', grid_search.best_score_)\n","\n","\n","################\n","# LGBMClassifier\n","################\n","# Melhores parâmetros GradientBoostingClassifier: {'learning_rate': 0.1, 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n","# Melhor score GradientBoostingClassifier: 0.7304776262351679\n","################\n","\n","# Espaço de hiperparâmetros para a busca\n","param_grid = {\n","    'num_leaves': [31, 127],\n","    'reg_alpha': [0.1, 0.5],\n","    'min_data_in_leaf': [30, 50, 100],\n","    'lambda_l1': [0, 1, 1.5],\n","    'lambda_l2': [0, 1]\n","}\n","# Modelo base\n","gbm = lgb.LGBMClassifier(boosting_type='gbdt', objective='binary', random_state=42)\n","# Configuração do GridSearchCV\n","grid_search = GridSearchCV(estimator=gbm, param_grid=param_grid, scoring='accuracy', cv=3, verbose=1, n_jobs=-1)\n","# Executa a busca em grade\n","grid_search.fit(X_train, y_train)\n","\n","# Exibe os melhores parâmetros encontrados\n","print('Melhores parâmetros LGBMClassifier:', grid_search.best_params_)\n","\n","# Exibe o melhor score\n","print('Melhor score LGBMClassifier:', grid_search.best_score_)\n","\n","################\n","# RandomForestClassifier\n","################\n","# Melhores parâmetros RandomForestClassifier: {'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 200}\n","# Melhor score RandomForestClassifier: 0.7252304225924031\n","################\n","\n","\n","# Espaço de hiperparâmetros para a busca\n","param_grid = {\n","    'n_estimators': [200, 300],\n","    'max_depth': [10, 20],\n","    'min_samples_split': [2, 5]\n","}\n","# Modelo base\n","rf_clf = RandomForestClassifier(random_state=42)\n","# Configuração do GridSearchCV\n","grid_search = GridSearchCV(estimator=rf_clf, param_grid=param_grid, scoring='accuracy', cv=3, verbose=1, n_jobs=-1)\n","# Executa a busca em grade\n","grid_search.fit(X_train, y_train)\n","\n","# Exibe os melhores parâmetros encontrados\n","print('Melhores parâmetros RandomForestClassifier:', grid_search.best_params_)\n","\n","# Exibe o melhor score\n","print('Melhor score RandomForestClassifier:', grid_search.best_score_)\n","\n","\n","################\n","# LogisticRegression\n","################\n","# Melhores parâmetros LogisticRegression: {'C': 0.03359818286283781, 'penalty': 'l1', 'solver': 'liblinear'}\n","# Melhor score (acurácia) LogisticRegression: 0.7261736861897804\n","################\n","# Definindo o espaço de parâmetros\n","param_grid = {\n","    'C': np.logspace(-4, 4, 20),  # Varia de 10^-4 a 10^4\n","    'penalty': ['l1', 'l2'],  # L1 é Lasso, L2 é Ridge\n","    'solver': ['liblinear']  # 'liblinear' é uma boa escolha para pequenos datasets e quando se usa a regularização L1\n","}\n","\n","# Instanciando o modelo de regressão logística\n","log_reg = LogisticRegression()\n","\n","# Instanciando o GridSearchCV\n","grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1, verbose=1)\n","\n","# Ajustando o GridSearchCV aos dados de treino\n","# Substitua X_train e y_train pelos seus dados de treinamento\n","grid_search.fit(X_train, y_train)\n","\n","# Exibindo os melhores parâmetros e o melhor score\n","print(\"Melhores parâmetros LogisticRegression:\", grid_search.best_params_)\n","print(\"Melhor score (acurácia) LogisticRegression:\", grid_search.best_score_)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["########\n","## Comparação do desempenho dos modelos.\n","## Pacotes\n","!pip install xgboost\n","!pip install catboost\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import roc_auc_score\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from catboost import CatBoostClassifier\n","from xgboost import XGBClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import roc_curve, auc"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["########\n","## Comparação do desempenho dos modelos.\n","\n","# Criação de df treino e teste\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(\n","    df.drop(columns=['DESFECHO']), # ou as colunas de features que você quer usar\n","    df['DESFECHO'], # a coluna alvo\n","    test_size=0.2, # define a proporção do teste para 20%\n","    random_state=42) # define a semente de aleatorização\n","\n","# Convertendo y_test para um array do NumPy para evitar problemas de indexação\n","y_test = y_test.to_numpy() if hasattr(y_test, 'to_numpy') else y_test\n","\n","# Modelos\n","catboost_model = CatBoostClassifier(depth=8, iterations=100, l2_leaf_reg=3, learning_rate=0.1, verbose=0)\n","xgboost_model = XGBClassifier(colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8)\n","gradientboost = GradientBoostingClassifier(learning_rate= 0.1, max_depth= 5, min_samples_leaf = 2, min_samples_split= 2, n_estimators= 200)\n","randomforest_model = RandomForestClassifier(max_depth=10, min_samples_split=5, n_estimators=200)\n","logistic_model = LogisticRegression(C=0.03359818286283781, penalty='l1', solver='liblinear')\n","\n","\n","models = [catboost_model, xgboost_model, gradientboost, randomforest_model, logistic_model]\n","model_names = [\"CatBoost\", \"XGBoost\", 'GradientBoost', \"RandomForest\", \"LogisticRegression\"]\n","\n","plt.figure(figsize=(10, 8))\n","\n","for model, name in zip(models, model_names):\n","    model.fit(X_train, y_train)\n","    y_pred_proba = model.predict_proba(X_test)[:, 1]\n","    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n","    roc_auc = auc(fpr, tpr)\n","    plt.plot(fpr, tpr, label=f'{name} AUC = {roc_auc:.2f}')\n","    \n","    # Bootstrap para calcular o intervalo de confiança\n","    n_bootstraps = 1000\n","    bootstrapped_scores = []\n","    \n","    rng = np.random.RandomState(42)  # Reproducibilidade\n","    for i in range(n_bootstraps):\n","        # Bootstrap por amostragem com reposição nos índices dos dados de teste\n","        indices = rng.randint(0, len(y_pred_proba), len(y_pred_proba))\n","        if len(np.unique(y_test[indices])) < 2:\n","            # Se após a amostragem, há menos de duas classes, pule esta iteração\n","            continue\n","\n","        score = roc_auc_score(y_test[indices], y_pred_proba[indices])\n","        bootstrapped_scores.append(score)\n","        \n","    sorted_scores = np.array(bootstrapped_scores)\n","    sorted_scores.sort()\n","    \n","    # Calculando a confiança de 95%\n","    confidence_lower = sorted_scores[int(0.025 * len(sorted_scores))]\n","    confidence_upper = sorted_scores[int(0.975 * len(sorted_scores))]\n","    \n","    print(f\"{name}: AUC = {roc_auc:.3f} (95% CI: {confidence_lower:.3f} - {confidence_upper:.3f})\")\n","\n","plt.plot([0, 1], [0, 1], 'k--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC Curves')\n","plt.legend(loc=\"lower right\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Modelo 3"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["---------- Fonte de dados ---------------\n","Arquivo:'G:\\Meu Drive\\Mestrado\\Dados\\consolidado_DESFECHO_V2.csv'\n","Criado após correção do agrupamento dos db origem\n","Contém todas variáveis\n","Processada variável DESFECHO (Variável EVOLUCAO agregada em DESFECHO e removida. registros com EVOLUCAO nulos removidos)\n","\n","----------\n","---------- Processamentos ---------------\n","0 - Removidos: registros notificados em 2022 \n","1 - Removidos: Numero de registros menores de 18a  6975\n","2 - CS_RACA agrupada em Raca (nulo = o, branco = 1, demais = 2)\n","----------\n","---------- Variáveis ---------------\n","VARIÁVEIS FINAIS:\n","'CS_SEXO', 'CS_ESCOL_N', 'FEBRE', 'TOSSE', 'DISPNEIA', 'DESC_RESP', 'SATURACAO', 'DIARREIA', 'OUTRO_SIN',  'OBESIDADE', 'OUT_MORBI', 'FADIGA', 'CL_tmp_p_inter', 'CT_IDADE', 'RacaBranca', 'CS_ZONA_CAT', 'DIABETES', 'CARDIOPATI'\n","\n","REMOVIDAS COLINEARIDADE: \n","'GARGANTA', 'ASMA', 'PNEUMOPATI',  'PERD_PALA', 'DOR_ABD', 'PERD_OLFT', 'VOMITO'\n","\n","----------\n","---------- OBS ---------------\n","\n","CS_RACA agrupada em Raca (nulo = o, branco = 1, demais = 2)\n","Variáveis 'DIABETES', 'CARDIOPATI' mantidas por desempenho modelo 1  melhor do que modelo 2\n","\n","\n","################\n","# GradientBoostingClassifier\n","################\n","# Melhores parâmetros GradientBoostingClassifier: {'learning_rate': 0.1, 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n","# Melhor score GradientBoostingClassifier: 0.7317455819848048\n","################\n","################\n","# CATBOOST\n","################\n","# Melhores parâmetros CatBoostClassifier: {'depth': 8, 'iterations': 100, 'l2_leaf_reg': 1, 'learning_rate': 0.1}\n","# Melhor score CatBoostClassifier: 0.7315962714372598\n","################\n","\n","################\n","# XGBOOST\n","################\n","# Melhores parâmetros XGBClassifier: {'colsample_bytree': 1, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300, 'subsample': 1}\n","# Melhor score XGBClassifier: 0.7322195848699681\n","################\n","\n","################\n","# RandomForestClassifier\n","################\n","# Melhores parâmetros RandomForestClassifier: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 300}\n","# Melhor score RandomForestClassifier: 0.7268135891141441\n","################\n","################\n","# LogisticRegression\n","################\n","# Melhores parâmetros LogisticRegression: {'C': 0.012742749857031334, 'penalty': 'l1', 'solver': 'liblinear'}\n","# Melhor score (acurácia) LogisticRegression: 0.7268349194138327\n","################\n","\n","\n","################\n","# LGBMClassifier\n","################\n","# Melhores parâmetros LGBMClassifier: {'lambda_l1': 0, 'lambda_l2': 1, 'min_data_in_leaf': 100, 'num_leaves': 127, 'reg_alpha': 0.1}\n","# Melhor score LGBMClassifier: 0.7325632349295033\n","################"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Carga do df\n","df = pd.read_csv('G:\\Meu Drive\\Mestrado\\Dados\\consolidado_DESFECHO_V2.csv')\n","\n","# Seleção das variáveis de interesse\n","df = df[[ 'DESFECHO',\n","'ANO_SEM_NOT',\n","\"DT_SIN_PRI\",\n","\"CS_SEXO\",\n","\"NU_IDADE_N\",\n","\"CS_RACA\",\n","\"CS_ESCOL_N\",\n","\"CS_ZONA\",\n","\"FEBRE\",\n","\"TOSSE\",\n","\"GARGANTA\",\n","\"DISPNEIA\",\n","\"DESC_RESP\",\n","\"SATURACAO\",\n","\"DIARREIA\",\n","\"VOMITO\",\n","\"OUTRO_SIN\",\n","\"FATOR_RISC\",\n","\"CARDIOPATI\",\n","\"ASMA\",\n","\"DIABETES\",\n","\"PNEUMOPATI\",\n","\"OBESIDADE\",\n","\"OUT_MORBI\",\n","\"DT_INTERNA\",\n","\"DOR_ABD\",\n","\"FADIGA\",\n","\"PERD_OLFT\",\n","\"PERD_PALA\"] ]\n","\n","#Removendo Registros de 2022\n","print('Numero de registros iniciais ', len(df))\n","print('Numero de registros menores de 2022 ', len(df['ANO_SEM_NOT'].astype(str).str[0:2] == \"22\"))\n","df = df[df['ANO_SEM_NOT'].astype(str).str[0:2] != \"22\"]\n","print('Numero de registros do df final ', len(df))\n","print()\n","\n","\n","#Removendo Registros de menores de 18a\n","print('Numero de registros iniciais ', len(df))\n","print('Numero de registros menores de 18a ', len(df[df.NU_IDADE_N < 18]))\n","df = df[df.NU_IDADE_N > 17]\n","print('Numero de registros do df final ', len(df))"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["#####################################\n","#### Processamento das variáveis\n","#####################################\n","#######\n","#### CRIACAO VARIÁVEL 'delta_sintomas_internação'\n","# Criando variáveis no df\n","df['DT_INTERNA'] = pd.to_datetime(df['DT_INTERNA'],format='%d/%m/%Y', errors = 'coerce')\n","df['DT_SIN_PRI'] = pd.to_datetime(df['DT_SIN_PRI'],format='%d/%m/%Y', errors = 'coerce')\n","df[ 'delta_sintomas_internação'] = (df[ 'DT_INTERNA'] - df[ 'DT_SIN_PRI']).dt.days\n","df['CL_tmp_p_inter'] = np.where(df['delta_sintomas_internação'].between(0, 4), 'tmp_p_inter_1',\n","         np.where(df['delta_sintomas_internação'].between(5, 7), 'tmp_p_inter_2',\n","         np.where(df['delta_sintomas_internação'].between(8, 10), 'tmp_p_inter_3',\n","         np.where(df['delta_sintomas_internação'].between(11, 19), 'tmp_p_inter_4',\n","         'tmp_p_inter_5'))))\n","df = df.drop(columns=(['DT_INTERNA', 'DT_SIN_PRI','delta_sintomas_internação']))\n","#######\n","## CS_SEXO\n","##\n","# M - 0\n","# H - 1\n","# I - 1 (sao 11 registros)\n","\n","df['CS_SEXO'] = df['CS_SEXO'].replace({'H': 1, 'I': 1, 'F': 0, 'M': 0})\n","#####\n","## NU_IDADE_N\n","## Criação da categoria CT_IDADE\n","\n","\n","# Criação de bins para categorizar as idades\n","# Definindo os intervalos (bins)\n","bins = [0, 17, 49, 59, 69, 79, 140]\n","\n","# Definindo os rótulos para os intervalos\n","labels = ['0-17', '18-49', '50-59', '60-69', '70-79', '80-140']\n","\n","# Agrupando os dados na coluna 'valor_contínuo' nos intervalos definidos\n","df['CT_IDADE'] = pd.cut(df['NU_IDADE_N'], bins=bins, labels=labels, right=True)\n","\n","df = df.drop(columns=('NU_IDADE_N'))\n","#####\n","## CS_RACA\n","## Criação da categoria RacaBranca\n","var = 'CS_RACA'\n","df[var] = df[var].fillna(0)\n","df['RacaBranca'] = np.where(df[var] == 1, 1, np.where(df[var] == 9, 3, np.where(df[var] == 0, 0, 2)))\n","df = df.drop(columns=(var))\n","#####\n","## CS_ESCOL_N\n","## criada categoria para nulos\n","df['CS_ESCOL_N'] = df['CS_ESCOL_N'].fillna(8)\n","#Categorizaçao da variávvel CS_ZONA\n","#8 – NULO\n","#1 – URBANO\n","#2 - RURAL, PERIRURAL, IGNORALDO\n","\n","df['CS_ZONA'] = df['CS_ZONA'].fillna(8)\n","df['CS_ZONA_CAT'] = np.where( df['CS_ZONA']== 1, 1 , np.where(df['CS_ZONA']== 8, 0, 2))\n","df = df.drop(columns=('CS_ZONA'))\n","# Padronização das variáveis de sintomas e fatores de risco\n","#0 – NULO\n","#1 – Sim\n","#2 - Não\n","#9 - IGNORALDO\n","for var in ['FEBRE', \"TOSSE\", \"GARGANTA\", \"DISPNEIA\", \"DESC_RESP\",\"SATURACAO\", \"DIARREIA\", \"VOMITO\", \"OUTRO_SIN\", \"ASMA\", \"DIABETES\",  \"CARDIOPATI\", \"PNEUMOPATI\", \"OBESIDADE\",\"OUT_MORBI\", \"DOR_ABD\", \"FADIGA\", \"PERD_OLFT\", \"PERD_PALA\"]:\n","  df[var] = df[var].fillna(0)\n","  df[var] = df[var].replace({9: 0})\n","# Padronização da FATOR_RISC\n","#1 – Sim\n","#2 - Não\n","#9 - IGNORALDO\n","var = 'FATOR_RISC'\n","df[var] = df[var].replace({2: 0, 'S': 1, 'N':0 })"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["################\n","### Remoçao do índice ano_semana\n","\n","df = df.drop(columns=('ANO_SEM_NOT'))"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["################\n","### Avaliação de Colinearidade\n","\n","corr = df.corr()\n","\n","# Gera um mapa de calor\n","plt.figure(figsize=(25, 25))\n","sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True, square=True, linewidths=.5)\n","\n","plt.title('Mapa de Calor da Colinearidade entre Variáveis')\n","plt.show()"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["# Definidas vairáveis finais removendo as de alta colinearidade\n","df = df.drop(columns=['GARGANTA', 'ASMA', 'PNEUMOPATI',  'PERD_PALA', 'DOR_ABD', 'PERD_OLFT', 'VOMITO'])"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["################\n","### Criação das variáveis Dummy\n","### NOTA - CS_SEXO é variável binaria, podem ser removidas desse processamento.\n","df = pd.get_dummies(df, columns=['CS_ESCOL_N', 'FEBRE', 'TOSSE', 'DISPNEIA', 'DESC_RESP', 'SATURACAO', 'DIARREIA', 'OUTRO_SIN',  'OBESIDADE', 'OUT_MORBI', 'FADIGA', 'CL_tmp_p_inter', 'CT_IDADE', 'RacaBranca', 'CS_ZONA_CAT'], drop_first=True)\n","\n","### Salvando banco de dados do modelo 2\n","df.to_csv('G:\\Meu Drive\\Mestrado\\Dados\\pre_modelagem_MODELO_3', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["################\n","### Carga das bibliotecas para treinamento do modelo\n","\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import train_test_split\n","!pip install catboost\n","from catboost import CatBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","!pip install xgboost\n","import xgboost as xgb\n","!pip install lightgbm\n","import lightgbm as lgb\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["################\n","### Otimização de hiperparametros\n","################\n","###\n","# Preparação do df\n","# Removendo a coluna ANO_SEM_NOT Não será usada no modelo geral.\n","# df = df.drop(columns=('ANO_SEM_NOT'))\n","df.FATOR_RISC = df.FATOR_RISC.astype(int)\n","#\n","###\n","\n","###\n","# Divisão em treino e teste\n","X_train, X_test, y_train, y_test = train_test_split(\n","    df.drop(columns=['DESFECHO']), # ou as colunas de features que você quer usar\n","    df['DESFECHO'], # a coluna alvo\n","    test_size=0.2, # define a proporção do teste para 20%\n","    random_state=42 # define a semente de aleatorização\n",")\n","#\n","###\n","\n","################\n","# GradientBoostingClassifier\n","################\n","# Melhores parâmetros GradientBoostingClassifier: {'learning_rate': 0.1, 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n","# Melhor score GradientBoostingClassifier: 0.7317455819848048\n","################\n","\n","\n","param_grid = {\n","    'n_estimators': [100, 200],\n","    'learning_rate': [0.01, 0.1],\n","    'max_depth': [3, 5],\n","    'min_samples_split': [2, 5],\n","    'min_samples_leaf': [1, 2]\n","}\n","\n","gb_clf = GradientBoostingClassifier(random_state=42)\n","grid_search = GridSearchCV(estimator=gb_clf, param_grid=param_grid, scoring='accuracy', cv=3, verbose=1, n_jobs=-1)\n","grid_search.fit(X_train, y_train)\n","\n","# Exibe os melhores parâmetros encontrados\n","print('Melhores parâmetros GradientBoostingClassifier:', grid_search.best_params_)\n","\n","# Exibe o melhor score\n","print('Melhor score GradientBoostingClassifier:', grid_search.best_score_)\n","\n","################\n","# CATBOOST\n","################\n","# Melhores parâmetros CatBoostClassifier: {'depth': 8, 'iterations': 100, 'l2_leaf_reg': 1, 'learning_rate': 0.1}\n","# Melhor score CatBoostClassifier: 0.7315962714372598\n","################\n","# Define o modelo\n","model = CatBoostClassifier()\n","\n","# Define o espaço de busca dos hiperparâmetros\n","param_grid = {\n","    'depth': [4, 6, 8],\n","    'learning_rate': [0.01, 0.05, 0.1],\n","    'iterations': [30, 50, 100],\n","    'l2_leaf_reg': [1, 3, 5]\n","}\n","\n","# Configura a busca em grade\n","grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1)\n","\n","# Executa a busca em grade\n","grid_search.fit(X_train, y_train)\n","\n","# Exibe os melhores parâmetros encontrados\n","print('Melhores parâmetros CatBoostClassifier:', grid_search.best_params_)\n","\n","# Exibe o melhor score\n","print('Melhor score CatBoostClassifier:', grid_search.best_score_)\n","\n","################\n","# XGBOOST\n","################\n","# Melhores parâmetros XGBClassifier: {'colsample_bytree': 1, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300, 'subsample': 1}\n","# Melhor score XGBClassifier: 0.7322195848699681\n","################\n","# Modelo base\n","model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n","\n","# Espaço de hiperparâmetros para a busca\n","param_grid = {\n","    'max_depth': [3, 4, 5],\n","    'learning_rate': [0.01, 0.1, 0.2],\n","    'n_estimators': [100, 200, 300],\n","    'subsample': [0.8, 1],\n","    'colsample_bytree': [0.8, 1],\n","}\n","\n","# Configuração do GridSearchCV\n","grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1)\n","\n","# Executa a busca em grade\n","grid_search.fit(X_train, y_train)\n","\n","# Melhores parâmetros e melhor score\n","print(\"Melhores parâmetros XGBClassifier:\", grid_search.best_params_)\n","print('Melhor score XGBClassifier:', grid_search.best_score_)\n","\n","\n","################\n","# LGBMClassifier\n","################\n","# Melhores parâmetros LGBMClassifier: {'lambda_l1': 0, 'lambda_l2': 1, 'min_data_in_leaf': 100, 'num_leaves': 127, 'reg_alpha': 0.1}\n","# Melhor score LGBMClassifier: 0.7325632349295033\n","################\n","\n","# Espaço de hiperparâmetros para a busca\n","param_grid = {\n","    'num_leaves': [31, 127],\n","    'reg_alpha': [0.1, 0.5],\n","    'min_data_in_leaf': [30, 50, 100],\n","    'lambda_l1': [0, 1, 1.5],\n","    'lambda_l2': [0, 1]\n","}\n","# Modelo base\n","gbm = lgb.LGBMClassifier(boosting_type='gbdt', objective='binary', random_state=42)\n","# Configuração do GridSearchCV\n","grid_search = GridSearchCV(estimator=gbm, param_grid=param_grid, scoring='accuracy', cv=3, verbose=1, n_jobs=-1)\n","# Executa a busca em grade\n","grid_search.fit(X_train, y_train)\n","\n","# Exibe os melhores parâmetros encontrados\n","print('Melhores parâmetros LGBMClassifier:', grid_search.best_params_)\n","\n","# Exibe o melhor score\n","print('Melhor score LGBMClassifier:', grid_search.best_score_)\n","\n","################\n","# RandomForestClassifier\n","################\n","# Melhores parâmetros RandomForestClassifier: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 300}\n","# Melhor score RandomForestClassifier: 0.7268135891141441\n","################\n","\n","\n","# Espaço de hiperparâmetros para a busca\n","param_grid = {\n","    'n_estimators': [200, 300],\n","    'max_depth': [10, 20],\n","    'min_samples_split': [2, 5]\n","}\n","# Modelo base\n","rf_clf = RandomForestClassifier(random_state=42)\n","# Configuração do GridSearchCV\n","grid_search = GridSearchCV(estimator=rf_clf, param_grid=param_grid, scoring='accuracy', cv=3, verbose=1, n_jobs=-1)\n","# Executa a busca em grade\n","grid_search.fit(X_train, y_train)\n","\n","# Exibe os melhores parâmetros encontrados\n","print('Melhores parâmetros RandomForestClassifier:', grid_search.best_params_)\n","\n","# Exibe o melhor score\n","print('Melhor score RandomForestClassifier:', grid_search.best_score_)\n","\n","\n","################\n","# LogisticRegression\n","################\n","# Melhores parâmetros LogisticRegression: {'C': 0.012742749857031334, 'penalty': 'l1', 'solver': 'liblinear'}\n","# Melhor score (acurácia) LogisticRegression: 0.7268349194138327\n","################\n","# Definindo o espaço de parâmetros\n","param_grid = {\n","    'C': np.logspace(-4, 4, 20),  # Varia de 10^-4 a 10^4\n","    'penalty': ['l1', 'l2'],  # L1 é Lasso, L2 é Ridge\n","    'solver': ['liblinear']  # 'liblinear' é uma boa escolha para pequenos datasets e quando se usa a regularização L1\n","}\n","\n","# Instanciando o modelo de regressão logística\n","log_reg = LogisticRegression()\n","\n","# Instanciando o GridSearchCV\n","grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1, verbose=1)\n","\n","# Ajustando o GridSearchCV aos dados de treino\n","# Substitua X_train e y_train pelos seus dados de treinamento\n","grid_search.fit(X_train, y_train)\n","\n","# Exibindo os melhores parâmetros e o melhor score\n","print(\"Melhores parâmetros LogisticRegression:\", grid_search.best_params_)\n","print(\"Melhor score (acurácia) LogisticRegression:\", grid_search.best_score_)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["########\n","## Comparação do desempenho dos modelos.\n","## Pacotes\n","!pip install xgboost\n","!pip install catboost\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import roc_auc_score\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from catboost import CatBoostClassifier\n","from xgboost import XGBClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import roc_curve, auc"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["########\n","## Comparação do desempenho dos modelos.\n","df.FATOR_RISC = df.FATOR_RISC.astype(int)\n","# Criação de df treino e teste\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(\n","    df.drop(columns=['DESFECHO']), # ou as colunas de features que você quer usar\n","    df['DESFECHO'], # a coluna alvo\n","    test_size=0.2, # define a proporção do teste para 20%\n","    random_state=42) # define a semente de aleatorização\n","\n","# Convertendo y_test para um array do NumPy para evitar problemas de indexação\n","y_test = y_test.to_numpy() if hasattr(y_test, 'to_numpy') else y_test\n","\n","# Modelos\n","catboost_model = CatBoostClassifier(depth=8, iterations=100, l2_leaf_reg=1, learning_rate=0.1, verbose=0)\n","xgboost_model = XGBClassifier(colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1)\n","gradientboost = GradientBoostingClassifier(learning_rate= 0.1, max_depth= 5, min_samples_leaf = 1, min_samples_split= 1, n_estimators= 200)\n","randomforest_model = RandomForestClassifier(max_depth=20, min_samples_split=5, n_estimators=300)\n","logistic_model = LogisticRegression(C=0.012742749857031334, penalty='l1', solver='liblinear')\n","\n","\n","models = [catboost_model, xgboost_model, gradientboost, randomforest_model, logistic_model]\n","model_names = [\"CatBoost\", \"XGBoost\", 'GradientBoost', \"RandomForest\", \"LogisticRegression\"]\n","\n","plt.figure(figsize=(10, 8))\n","\n","for model, name in zip(models, model_names):\n","    model.fit(X_train, y_train)\n","    y_pred_proba = model.predict_proba(X_test)[:, 1]\n","    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n","    roc_auc = auc(fpr, tpr)\n","    plt.plot(fpr, tpr, label=f'{name} AUC = {roc_auc:.2f}')\n","    \n","    # Bootstrap para calcular o intervalo de confiança\n","    n_bootstraps = 1000\n","    bootstrapped_scores = []\n","    \n","    rng = np.random.RandomState(42)  # Reproducibilidade\n","    for i in range(n_bootstraps):\n","        # Bootstrap por amostragem com reposição nos índices dos dados de teste\n","        indices = rng.randint(0, len(y_pred_proba), len(y_pred_proba))\n","        if len(np.unique(y_test[indices])) < 2:\n","            # Se após a amostragem, há menos de duas classes, pule esta iteração\n","            continue\n","\n","        score = roc_auc_score(y_test[indices], y_pred_proba[indices])\n","        bootstrapped_scores.append(score)\n","        \n","    sorted_scores = np.array(bootstrapped_scores)\n","    sorted_scores.sort()\n","    \n","    # Calculando a confiança de 95%\n","    confidence_lower = sorted_scores[int(0.025 * len(sorted_scores))]\n","    confidence_upper = sorted_scores[int(0.975 * len(sorted_scores))]\n","    \n","    print(f\"{name}: AUC = {roc_auc:.3f} (95% CI: {confidence_lower:.3f} - {confidence_upper:.3f})\")\n","\n","plt.plot([0, 1], [0, 1], 'k--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC Curves')\n","plt.legend(loc=\"lower right\")\n","plt.show()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM1D1ZAYOf5OEJ2AcMqDZrF","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
